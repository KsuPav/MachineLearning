{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная №2. \n",
    "# Алгоритмы классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загружаем нужные модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score , recall_score , f1_score\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Считаем обработанный в лабороторной №1 датасет и показываем первые строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "      <th>College</th>\n",
       "      <th>School</th>\n",
       "      <th>University</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>23.55</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>28.38</td>\n",
       "      <td>75.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>39.40</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>27.08</td>\n",
       "      <td>73.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>22.36</td>\n",
       "      <td>75.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male   age  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1  58.0              1        20.0     0.0                0   \n",
       "1     0  49.0              0         0.0     0.0                0   \n",
       "2     0  59.0              0         0.0     1.0                0   \n",
       "3     1  36.0              0         0.0     0.0                0   \n",
       "4     0  60.0              0         0.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    207.0  110.0   80.0  23.55       78.0     78.0   \n",
       "1             0         0    239.0  143.0   93.0  28.38       75.0     87.0   \n",
       "2             0         0    234.0  181.0  107.0  39.40       80.0     90.0   \n",
       "3             0         0    194.0  117.0   90.0  27.08       73.0     87.0   \n",
       "4             0         0    328.0  127.0   70.0  22.36       75.0     63.0   \n",
       "\n",
       "   TenYearCHD  College  School  University  other  \n",
       "0           0        1       0           0      0  \n",
       "1           0        1       0           0      0  \n",
       "2           1        0       1           0      0  \n",
       "3           0        0       0           0      1  \n",
       "4           1        0       0           1      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=read_csv('remastered_dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Делим выборку на трейн и тест в соотношении 30% для теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваю выборку на трейн и тест. Для теста выделяю 30% выборки.\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop('TenYearCHD',axis=1), dataset['TenYearCHD'], test_size=0.3,shuffle=True,random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создаем функцию для подсчета метрик "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred, Y_test):\n",
    "    \n",
    "    \n",
    "    print(\"Accuracy: \", (pred==Y_test).mean())\n",
    "    print(\"Pprecision: \", precision_score(pred, Y_test, average='micro'))\n",
    "    print(\"Recall: \", recall_score(pred, Y_test, average='micro'))\n",
    "    print(\"F1: \", f1_score(pred, Y_test, average='micro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Я реализовал логистическую регрессию в виде класса с 2 публичными методами. fit - для обучения, predict - для предсказания\n",
    "class LogReg:\n",
    "    #задаем количество итераций при инициализации класса 100000\n",
    "    def __init__(self,num_iter = 100000):\n",
    "        self.num_iter=num_iter\n",
    "        self.beta=1\n",
    "        \n",
    "     #метод обучающий модель   \n",
    "    def fit(self,x,y):\n",
    "        #задаем матрицу весов в виде единичной матрицы \n",
    "        self.beta = np.ones(x.shape[1])\n",
    "        for i in range(self.num_iter):\n",
    "            h = self._sigmoid(x, self.beta)#считаем сигмойду\n",
    "            gradient = self._gradient_spusk(x, h, y)#спускаемся по градиенту\n",
    "            self.beta =self._weight_update(self.beta, 0.1, gradient)#обновляем веса\n",
    "    \n",
    "    #приватный метод, считающий сигмойду\n",
    "    def _sigmoid(self,X, weight):\n",
    "        z = np.dot(X, weight)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    #приватная функция для градиентного шага\n",
    "    def _gradient_spusk(self,X, H, Y):\n",
    "        return np.dot(X.T, (H - Y)) / Y.shape[0]\n",
    "    \n",
    "    #приватная функция для обноления весов\n",
    "    def _weight_update(self,weight, learning_rate, gradient):\n",
    "        return weight - learning_rate * gradient\n",
    "    \n",
    "    \n",
    "    def predict(self,test):\n",
    "        final_result=[]\n",
    "        \n",
    "        #приминяем сигмойду к тестовым данным\n",
    "        result = self._sigmoid(test, self.beta)\n",
    "        \n",
    "        #выбираем  метки для теста \n",
    "        for i in result:\n",
    "            final_result.append(self._onepred(i))\n",
    "        \n",
    "        \n",
    "        return final_result\n",
    "        \n",
    "        \n",
    "        \n",
    "    #приватная функция для одного предсказания    \n",
    "    def _onepred(self,x):\n",
    "        if x < 0.5:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-f7a648a8a967>:20: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики на обучающей выборки \n",
      "Accuracy:  0.851652056641942\n",
      "Pprecision:  0.851652056641942\n",
      "Recall:  0.851652056641942\n",
      "F1:  0.851652056641942\n",
      "Метрики на тестовой выборки \n",
      "Accuracy:  0.839622641509434\n",
      "Pprecision:  0.839622641509434\n",
      "Recall:  0.839622641509434\n",
      "F1:  0.839622641509434\n"
     ]
    }
   ],
   "source": [
    "#обучаю свою модель \n",
    "my_lg=LogReg()\n",
    "my_lg.fit(X_train,y_train)\n",
    "#делаем предсказания на трейне и на тесте и смотрим метрики\n",
    "print('Метрики на обучающей выборки ')\n",
    "metrics(my_lg.predict(X_train),y_train)\n",
    "print('Метрики на тестовой выборки ')\n",
    "metrics(my_lg.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики на обучающей выборки \n",
      "Accuracy:  0.8577208361429535\n",
      "Pprecision:  0.8577208361429535\n",
      "Recall:  0.8577208361429535\n",
      "F1:  0.8577208361429536\n",
      "Метрики на тестовой выборки \n",
      "Accuracy:  0.8443396226415094\n",
      "Pprecision:  0.8443396226415094\n",
      "Recall:  0.8443396226415094\n",
      "F1:  0.8443396226415094\n"
     ]
    }
   ],
   "source": [
    "#обучаю модель из sklearn\n",
    "sk_lg=LogisticRegression( max_iter=1000000)\n",
    "sk_lg.fit(X_train,y_train)\n",
    "#делаем предсказания на трейне и на тесте и смотрим метрики\n",
    "print('Метрики на обучающей выборки ')\n",
    "metrics(sk_lg.predict(X_train),y_train)\n",
    "print('Метрики на тестовой выборки ')\n",
    "metrics(sk_lg.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы о моделях по метрикам\n",
    "- Моя модель и модель из sklearn не переобучились, т к разница  на метриках между трейном и тестом минимальна.\n",
    "- Разница метрик на трейне и тесте между моей моделью и моделью из sklearn минимальна \n",
    "- Обе модели показали достаточно неплохой результат примерно 0.85 по метрикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Я реализовал SVM в виде класса MYSVM с двумя публичными методами fit- для обучения, predict - для предсказания \n",
    "class MYSVM(object):\n",
    "    # при инициализации класса задается сразу _etha -шаг градиентного спуска,_alpha – коэффициент быстроты\n",
    "    #пропорционального уменьшения весов, _epochs – количество эпох обучения\n",
    "    def __init__(self, etha=0.1, alpha=0.2, epochs=990):\n",
    "        self._epochs = epochs\n",
    "        self._etha = etha\n",
    "        self._alpha = alpha\n",
    "        self._w = None\n",
    "        \n",
    "        \n",
    "    #метод для обучения модели    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \n",
    "        \n",
    "        for i in range(len(Y_train)):\n",
    "            if Y_train.iloc[i] == 0:\n",
    "                Y_train.iloc[i] = -1\n",
    "        \n",
    "        #добавляем в конец каждого вектора число 1 \n",
    "        X_train = self._add_bias_feature(X_train)\n",
    "        self._w = np.random.normal(loc=0, scale=0.05, size=X_train.shape[1])#задаем первые веса\n",
    "        \n",
    "        \n",
    "        \n",
    "        for epoch in range(self._epochs): \n",
    "            \n",
    "            for i,x in enumerate(X_train):\n",
    "                margin = Y_train.iloc[i]*np.dot(self._w,X_train[i])\n",
    "                if margin >= 1: # классифицируем верно\n",
    "                    self._w = self._w - self._etha*self._alpha*self._w/self._epochs\n",
    "                    \n",
    "                else: # классифицируем неверно или попадаем на полосу разделения при 0<m<1\n",
    "                    self._w = self._w +\\\n",
    "                    self._etha*(Y_train.iloc[i]*X_train[i] - self._alpha*self._w/self._epochs)\n",
    "                    \n",
    "                \n",
    "        for i in range(len(Y_train)):\n",
    "            if Y_train.iloc[i]==-1:\n",
    "                Y_train.iloc[i]=0\n",
    "     \n",
    "    #Приватный метод , добовляющей в конец каждого вектора чисор 1 \n",
    "    def _add_bias_feature(self,a):\n",
    "        \n",
    "        a_extended = np.zeros((a.shape[0],a.shape[1]+1))\n",
    "        a_extended[:,:-1] = a\n",
    "        a_extended[:,-1] = int(1)  \n",
    "        return a_extended\n",
    "    \n",
    "    \n",
    "     #метод для предсказания \n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        #X_extended = self._add_bias_feature(X)\n",
    "        for i in range(len(X)):\n",
    "            y_pred.append(np.sign(1+np.dot(self._w[1:],X.iloc[i])))\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i]==-1:\n",
    "                y_pred[i]=0\n",
    "\n",
    "        return y_pred         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "метрики на обучении\n",
      "Accuracy:  0.8479433580579906\n",
      "Pprecision:  0.8479433580579906\n",
      "Recall:  0.8479433580579906\n",
      "F1:  0.8479433580579906\n",
      "метрики на тесте\n",
      "Accuracy:  0.839622641509434\n",
      "Pprecision:  0.839622641509434\n",
      "Recall:  0.839622641509434\n",
      "F1:  0.839622641509434\n"
     ]
    }
   ],
   "source": [
    "my_svm=MYSVM()\n",
    "my_svm.fit(X_train,y_train)\n",
    "print('метрики на обучении')\n",
    "metrics(my_svm.predict(X_train),y_train)\n",
    "print('метрики на тесте')\n",
    "metrics(my_svm.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "метрики на обучении\n",
      "Accuracy:  0.851652056641942\n",
      "Pprecision:  0.851652056641942\n",
      "Recall:  0.851652056641942\n",
      "F1:  0.851652056641942\n",
      "метрики на тесте\n",
      "Accuracy:  0.839622641509434\n",
      "Pprecision:  0.839622641509434\n",
      "Recall:  0.839622641509434\n",
      "F1:  0.839622641509434\n"
     ]
    }
   ],
   "source": [
    "sk_svm = svm.SVC()\n",
    "sk_svm.fit(X_train, y_train)\n",
    "print('метрики на обучении')\n",
    "metrics(sk_svm.predict(X_train),y_train)\n",
    "print('метрики на тесте')\n",
    "metrics(sk_svm.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы \n",
    "- Моя модель не переобучилась, т к разница  на метриках между трейном и тестом минимальна.\n",
    "- Моделт из sklearn не переобучилась, т к разница  на метриках между трейном и тестом минимальна.\n",
    "- Моя модель показывает себя хуже по метрикам на трейне чем модель из sklearn на трейне, но при этом моя модель показывает  такие же метрики как и sklearn на тесте. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Я реализовать дерево решений в виде класса MyDT с двуми публичными методами , fit - для обучения, predict - для предсказания \n",
    "#остальные методы приватные и используются в публичных\n",
    "class MyDT():\n",
    "    \n",
    "    # объявляем характеристики класса\n",
    "    def __init__(self, max_depth=3, min_size=10):\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.value = 0\n",
    "        self.feature_idx = -1\n",
    "        self.feature_threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    # процедура обучения - сюда передается обучающая выборка\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            if y.iloc[i] == 0:\n",
    "                y.iloc[i] = -1\n",
    "        \n",
    "        \n",
    "        # начальное значение - среднее значение y\n",
    "        self.value = y.mean()\n",
    "        # начальная ошибка - mse между значением в листе (пока нет\n",
    "        # разбиения, это среднее по всем объектам) и объектами\n",
    "        base_error = ((y - self.value) ** 2).sum()\n",
    "        error = base_error\n",
    "        flag = 0\n",
    "        \n",
    "        # пришли в максимальную глубину\n",
    "        if self.max_depth <= 1:\n",
    "            return\n",
    "    \n",
    "        dim_shape = X.shape[1]\n",
    "        \n",
    "        left_value, right_value = 0, 0\n",
    "        \n",
    "        for feat in range(dim_shape):\n",
    "            \n",
    "            prev_error1, prev_error2 = base_error, 0 \n",
    "            if feat==0:\n",
    "                idxs = np.argsort(X[:, feat])\n",
    "            \n",
    "            # переменные для быстрого переброса суммы\n",
    "            mean1, mean2 = y.mean(), 0\n",
    "            sm1, sm2 = y.sum(), 0\n",
    "            \n",
    "            N = X.shape[0]\n",
    "            N1, N2 = N, 0\n",
    "            thres = 1\n",
    "            \n",
    "            while thres < N - 1:\n",
    "                N1 -= 1\n",
    "                N2 += 1\n",
    "\n",
    "                idx = idxs[thres]\n",
    "                x = X[int(idx), feat]\n",
    "                \n",
    "                # вычисляем дельты - по ним в основном будет делаться переброс\n",
    "                delta1 = (sm1 - y.iloc[idx]) * 1.0 / N1 - mean1\n",
    "                delta2 = (sm2 + y.iloc[idx]) * 1.0 / N2 - mean2\n",
    "                \n",
    "                # увеличиваем суммы\n",
    "                sm1 -= y.iloc[idx]\n",
    "                sm2 += y.iloc[idx]\n",
    "                \n",
    "                # пересчитываем ошибки за O(1)\n",
    "                prev_error1 += (delta1**2) * N1 \n",
    "                prev_error1 -= (y.iloc[idx] - mean1)**2 \n",
    "                prev_error1 -= 2 * delta1 * (sm1 - mean1 * N1)\n",
    "                mean1 = sm1/N1\n",
    "                \n",
    "                prev_error2 += (delta2**2) * N2 \n",
    "                prev_error2 += (y.iloc[idx] - mean2)**2 \n",
    "                prev_error2 -= 2 * delta2 * (sm2 - mean2 * N2)\n",
    "                mean2 = sm2/N2\n",
    "                \n",
    "                # пропускаем близкие друг к другу значения\n",
    "                if thres < N - 1 and np.abs(x - X[idxs[thres + 1], feat]) < 1e-5:\n",
    "                    thres += 1\n",
    "                    continue\n",
    "                \n",
    "                # 2 условия, чтобы осуществить сплит - уменьшение ошибки \n",
    "                # и минимальное кол-о эл-в в каждом листе\n",
    "                if (prev_error1 + prev_error2 < error):\n",
    "                    if (min(N1,N2) > self.min_size):\n",
    "                    \n",
    "                        # переопределяем самый лучший признак и границу по нему\n",
    "                        self.feature_idx, self.feature_threshold = feat, x\n",
    "                        # переопределяем значения в листах\n",
    "                        left_value, right_value = mean1, mean2\n",
    "\n",
    "                        # флаг - значит сделали хороший сплит\n",
    "                        flag = 1\n",
    "                        error = prev_error1 + prev_error2\n",
    "                                     \n",
    "                thres += 1\n",
    " \n",
    "        # ничего не разделили, выходим\n",
    "        if self.feature_idx == -1:\n",
    "            return\n",
    "        \n",
    "        self.left = MyDT(self.max_depth - 1)\n",
    "        # print (\"Левое поддерево с глубиной %d\"%(self.max_depth - 1))\n",
    "        self.left.value = left_value\n",
    "        self.right = MyDT(self.max_depth - 1)\n",
    "        # print (\"Правое поддерево с глубиной %d\"%(self.max_depth - 1))\n",
    "        self.right.value = right_value\n",
    "        \n",
    "        idxs_l = (X[:, self.feature_idx] > self.feature_threshold)\n",
    "        idxs_r = (X[:, self.feature_idx] <= self.feature_threshold)\n",
    "    \n",
    "        self.left.fit(X[idxs_l, :], y[idxs_l])\n",
    "        self.right.fit(X[idxs_r, :], y[idxs_r])\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            if y.iloc[i]==-1:\n",
    "                y.iloc[i]=0\n",
    "        \n",
    "    def __predict(self, x):\n",
    "        if self.feature_idx == -1:\n",
    "            return self.value\n",
    "        \n",
    "        if x[self.feature_idx] > self.feature_threshold:\n",
    "            return self.left.__predict(x)\n",
    "        else:\n",
    "            return self.right.__predict(x)\n",
    "    \n",
    "    #метод для финального расставления меток \n",
    "    def _prediction(self,x):\n",
    "        if x < 0:\n",
    "            \n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    #Метод для предсказания \n",
    "    def predict(self, X):\n",
    "        y = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            y[i] = self.__predict(X[i])\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            y[i]=self._prediction(y[i])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "метрики на обучении\n",
      "Accuracy:  0.851652056641942\n",
      "Pprecision:  0.851652056641942\n",
      "Recall:  0.851652056641942\n",
      "F1:  0.851652056641942\n",
      "метрики на тесте\n",
      "Accuracy:  0.839622641509434\n",
      "Pprecision:  0.839622641509434\n",
      "Recall:  0.839622641509434\n",
      "F1:  0.839622641509434\n"
     ]
    }
   ],
   "source": [
    "my_dt=MyDT()\n",
    "my_dt.fit(X_train.values,y_train)\n",
    "print('метрики на обучении')\n",
    "metrics(my_dt.predict(X_train.values),y_train)\n",
    "print('метрики на тесте')\n",
    "metrics(my_dt.predict(X_test.values),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "метрики на обучении\n",
      "Accuracy:  0.8550236008091706\n",
      "Pprecision:  0.8550236008091706\n",
      "Recall:  0.8550236008091706\n",
      "F1:  0.8550236008091706\n",
      "метрики на тесте\n",
      "Accuracy:  0.8388364779874213\n",
      "Pprecision:  0.8388364779874213\n",
      "Recall:  0.8388364779874213\n",
      "F1:  0.8388364779874213\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=10)\n",
    "dt.fit(X_train,y_train)\n",
    "print('метрики на обучении')\n",
    "metrics(dt.predict(X_train.values),y_train)\n",
    "print('метрики на тесте')\n",
    "metrics(dt.predict(X_test.values),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы \n",
    "- Моя модель практичиски не переобучилась, т к разница  на метриках между трейном и тестом минимальна.\n",
    "- Моделт из sklearn практичиски не переобучилась, т к разница  на метриках между трейном и тестом минимальна.\n",
    "- Моя модель показывает себя хуже по метрикам на трейне чем модель из sklearn на трейне(0.004) и на тесте (0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
